# 03-unixfs: íŒŒì¼ì‹œìŠ¤í…œ ì¶”ìƒí™”ì™€ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬

## ğŸ¯ í•™ìŠµ ëª©í‘œ

ì´ ëª¨ë“ˆì„ í†µí•´ ë‹¤ìŒì„ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:
- **UnixFS**ì˜ ê°œë…ê³¼ IPFSì—ì„œ íŒŒì¼ì„ í‘œí˜„í•˜ëŠ” ë°©ë²•
- **ì²­í‚¹(Chunking)** ì „ëµê³¼ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬
- **íŒŒì¼ê³¼ ë””ë ‰í„°ë¦¬** êµ¬ì¡°ì˜ IPFS ì €ì¥ ë°©ì‹
- **Merkle DAG**ë¥¼ í†µí•œ íš¨ìœ¨ì ì¸ íŒŒì¼ ê²€ì¦
- **ìŠ¤íŠ¸ë¦¬ë°** ê¸°ë°˜ íŒŒì¼ ì…ì¶œë ¥ê³¼ ì„±ëŠ¥ ìµœì í™”
- **íŒŒì¼ ë©”íƒ€ë°ì´í„°** ê´€ë¦¬ì™€ MIME íƒ€ì… ì²˜ë¦¬

## ğŸ“‹ ì‚¬ì „ ìš”êµ¬ì‚¬í•­

- **00-block-cid** ëª¨ë“ˆ ì™„ë£Œ (Blockê³¼ CID ì´í•´)
- **01-persistent** ëª¨ë“ˆ ì™„ë£Œ (ë°ì´í„° ì˜ì†ì„± ì´í•´)
- **02-dag-ipld** ëª¨ë“ˆ ì™„ë£Œ (DAGì™€ IPLD ì´í•´)
- íŒŒì¼ì‹œìŠ¤í…œì˜ ê¸°ë³¸ ê°œë… (íŒŒì¼, ë””ë ‰í„°ë¦¬, ê²½ë¡œ)
- ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬ì™€ I/O ê°œë…

## ğŸ”‘ í•µì‹¬ ê°œë…

### UnixFSë€?

**UnixFS**ëŠ” IPFSì—ì„œ íŒŒì¼ê³¼ ë””ë ‰í„°ë¦¬ë¥¼ í‘œí˜„í•˜ê¸° ìœ„í•œ ë°ì´í„° í˜•ì‹ì…ë‹ˆë‹¤:

```
ì¼ë°˜ íŒŒì¼ì‹œìŠ¤í…œ: /home/user/document.txt
UnixFS in IPFS: QmHash... (íŒŒì¼ ë‚´ìš©) + ë©”íƒ€ë°ì´í„°
```

### ì²­í‚¹(Chunking) ì „ëµ

ëŒ€ìš©ëŸ‰ íŒŒì¼ì€ ì‘ì€ ì²­í¬ë¡œ ë¶„í• ë˜ì–´ ì €ì¥ë©ë‹ˆë‹¤:

```
í° íŒŒì¼ (10MB)
    â†“ ì²­í‚¹
Chunk1 (256KB) â†’ Chunk2 (256KB) â†’ ... â†’ Chunk40 (256KB)
    â†“ Merkle DAG
      Root
    â†™  â†“  â†˜
  C1   C2   C3...
```

### íŒŒì¼ êµ¬ì¡° ê³„ì¸µ

```
UnixFS Node
â”œâ”€ Type: File | Directory | Symlink
â”œâ”€ Data: ì‹¤ì œ ë‚´ìš© ë˜ëŠ” ì²­í¬ ì°¸ì¡°
â”œâ”€ Links: í•˜ìœ„ ì²­í¬/íŒŒì¼ì— ëŒ€í•œ CID ë§í¬
â””â”€ Metadata: í¬ê¸°, ê¶Œí•œ, íƒ€ì„ìŠ¤íƒ¬í”„ ë“±
```

### Merkle DAGì˜ ì¥ì 

1. **ë¬´ê²°ì„± ê²€ì¦**: ë‹¨ì¼ í•´ì‹œë¡œ ì „ì²´ íŒŒì¼ ê²€ì¦
2. **íš¨ìœ¨ì  ë™ê¸°í™”**: ë³€ê²½ëœ ì²­í¬ë§Œ ì „ì†¡
3. **ì¤‘ë³µ ì œê±°**: ë™ì¼í•œ ì²­í¬ëŠ” í•œ ë²ˆë§Œ ì €ì¥
4. **ë³‘ë ¬ ì²˜ë¦¬**: ì²­í¬ ë‹¨ìœ„ ë…ë¦½ì  ì²˜ë¦¬

## ğŸ’» ì½”ë“œ ë¶„ì„

### 1. UnixFS Wrapper ì„¤ê³„

```go
// pkg/unixfs.go:21-31
type UnixFsWrapper struct {
    dagService   format.DAGService
    dagWrapper   *dag.DagWrapper
    chunker      chunk.Splitter
    maxChunkSize int
}

func New(maxChunkSize int) (*UnixFsWrapper, error) {
    if maxChunkSize <= 0 {
        maxChunkSize = DefaultChunkSize // 256KB
    }
    // DAG ì„œë¹„ìŠ¤ì™€ ì²­ì»¤ ì´ˆê¸°í™”
}
```

**ì„¤ê³„ íŠ¹ì§•**:
- **dag.DagWrapper** ì¬ì‚¬ìš©ìœ¼ë¡œ IPLD ê¸°ëŠ¥ í™œìš©
- **chunk.Splitter**ë¡œ ìœ ì—°í•œ ì²­í‚¹ ì „ëµ
- **ì„¤ì • ê°€ëŠ¥í•œ ì²­í¬ í¬ê¸°**ë¡œ ìš©ë„ë³„ ìµœì í™”

### 2. íŒŒì¼ ì €ì¥ (ì²­í‚¹ í¬í•¨)

```go
// pkg/unixfs.go:60-95
func (ufs *UnixFsWrapper) Put(ctx context.Context, file files.File) (cid.Cid, error) {
    // 1. íŒŒì¼ì„ ì²­í¬ë¡œ ë¶„í• 
    chunker := chunk.NewSizeSplitter(file, int64(ufs.maxChunkSize))

    // 2. ì²­í¬ë“¤ì„ ê°œë³„ì ìœ¼ë¡œ ì €ì¥
    var links []*format.Link
    totalSize := uint64(0)

    for {
        chunk, err := chunker.NextBytes()
        if err != nil {
            if err == io.EOF {
                break
            }
            return cid.Undef, fmt.Errorf("failed to get next chunk: %w", err)
        }

        // 3. ê° ì²­í¬ë¥¼ UnixFS ë…¸ë“œë¡œ ìƒì„±
        chunkNode := &dag.ProtoNode{}
        chunkNode.SetData(unixfs.FilePBData(chunk, uint64(len(chunk))))

        // 4. ì²­í¬ ì €ì¥ ë° ë§í¬ ìƒì„±
        err = ufs.dagService.Add(ctx, chunkNode)
        if err != nil {
            return cid.Undef, fmt.Errorf("failed to add chunk: %w", err)
        }

        links = append(links, &format.Link{
            Name: "",
            Size: uint64(len(chunk)),
            Cid:  chunkNode.Cid(),
        })
        totalSize += uint64(len(chunk))
    }

    // 5. ë£¨íŠ¸ ë…¸ë“œ ìƒì„± (ëª¨ë“  ì²­í¬ë¥¼ ë§í¬)
    rootNode := &dag.ProtoNode{}
    rootNode.SetLinks(links)
    rootNode.SetData(unixfs.FilePBData(nil, totalSize))

    err = ufs.dagService.Add(ctx, rootNode)
    return rootNode.Cid(), err
}
```

**í•µì‹¬ ê³¼ì •**:
1. **ì²­í‚¹**: íŒŒì¼ì„ ì„¤ì •ëœ í¬ê¸°ë¡œ ë¶„í• 
2. **ì²­í¬ ì €ì¥**: ê° ì²­í¬ë¥¼ UnixFS ë…¸ë“œë¡œ ì €ì¥
3. **ë§í¬ ìˆ˜ì§‘**: ì²­í¬ CIDë“¤ì„ ìˆ˜ì§‘
4. **ë£¨íŠ¸ ìƒì„±**: ëª¨ë“  ì²­í¬ë¥¼ ë§í¬í•˜ëŠ” ë£¨íŠ¸ ë…¸ë“œ
5. **ë©”íƒ€ë°ì´í„°**: íŒŒì¼ í¬ê¸° ë“± ì •ë³´ í¬í•¨

### 3. íŒŒì¼ ê²€ìƒ‰ (ìŠ¤íŠ¸ë¦¬ë°)

```go
// pkg/unixfs.go:98-130
func (ufs *UnixFsWrapper) Get(ctx context.Context, c cid.Cid) (files.Node, error) {
    // 1. ë£¨íŠ¸ ë…¸ë“œ ì¡°íšŒ
    rootNode, err := ufs.dagService.Get(ctx, c)
    if err != nil {
        return nil, fmt.Errorf("failed to get root node: %w", err)
    }

    // 2. UnixFS ë©”íƒ€ë°ì´í„° íŒŒì‹±
    fsNode, err := unixfs.FSNodeFromBytes(rootNode.RawData())
    if err != nil {
        return nil, fmt.Errorf("failed to parse UnixFS node: %w", err)
    }

    switch fsNode.Type() {
    case unixfs.TFile:
        return ufs.getFile(ctx, rootNode, fsNode)
    case unixfs.TDirectory:
        return ufs.getDirectory(ctx, rootNode, fsNode)
    default:
        return nil, fmt.Errorf("unsupported UnixFS type: %v", fsNode.Type())
    }
}

func (ufs *UnixFsWrapper) getFile(ctx context.Context, rootNode format.Node,
                                 fsNode *unixfs.FSNode) (files.File, error) {
    // 3. íŒŒì¼ ë¦¬ë” ìƒì„± (ìŠ¤íŠ¸ë¦¬ë°)
    dagReader, err := uio.NewDagReader(ctx, rootNode, ufs.dagService)
    if err != nil {
        return nil, fmt.Errorf("failed to create DAG reader: %w", err)
    }

    // 4. ì²­í¬ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì½ëŠ” ìŠ¤íŠ¸ë¦¼ ë°˜í™˜
    return files.NewReaderFile(dagReader), nil
}
```

### 4. ë””ë ‰í„°ë¦¬ ì²˜ë¦¬

```go
// pkg/unixfs.go:170-200
func (ufs *UnixFsWrapper) putDirectory(ctx context.Context, dir files.Directory) (cid.Cid, error) {
    // 1. ë””ë ‰í„°ë¦¬ ë…¸ë“œ ìƒì„±
    dirNode := &dag.ProtoNode{}
    dirNode.SetData(unixfs.FolderPBData())

    // 2. ë””ë ‰í„°ë¦¬ ë‚´ íŒŒì¼/í•˜ìœ„ ë””ë ‰í„°ë¦¬ ì²˜ë¦¬
    entries := dir.Entries()
    for entries.Next() {
        entry := entries.Node()
        entryName := entries.Name()

        // 3. ì¬ê·€ì ìœ¼ë¡œ í•˜ìœ„ í•­ëª© ì²˜ë¦¬
        var entryCID cid.Cid
        var err error

        switch entry := entry.(type) {
        case files.File:
            entryCID, err = ufs.Put(ctx, entry)
        case files.Directory:
            entryCID, err = ufs.putDirectory(ctx, entry)
        default:
            return cid.Undef, fmt.Errorf("unsupported file type")
        }

        if err != nil {
            return cid.Undef, fmt.Errorf("failed to add entry %s: %w", entryName, err)
        }

        // 4. ë””ë ‰í„°ë¦¬ ë§í¬ ì¶”ê°€
        err = dirNode.AddNodeLink(entryName, &dag.ProtoNode{})
        if err != nil {
            return cid.Undef, fmt.Errorf("failed to add link: %w", err)
        }
    }

    // 5. ë””ë ‰í„°ë¦¬ ë…¸ë“œ ì €ì¥
    err := ufs.dagService.Add(ctx, dirNode)
    return dirNode.Cid(), err
}
```

### 5. ê²½ë¡œ ê¸°ë°˜ íŒŒì¼ ì ‘ê·¼

```go
// pkg/unixfs.go:240-270
func (ufs *UnixFsWrapper) GetPath(ctx context.Context, rootCID cid.Cid, path string) (files.Node, error) {
    if path == "" || path == "/" {
        return ufs.Get(ctx, rootCID)
    }

    // 1. ê²½ë¡œ íŒŒì‹±
    pathSegments := strings.Split(strings.Trim(path, "/"), "/")
    currentCID := rootCID

    // 2. ê²½ë¡œë¥¼ ë”°ë¼ ìˆœì°¨ì ìœ¼ë¡œ íƒìƒ‰
    for _, segment := range pathSegments {
        // í˜„ì¬ ë…¸ë“œ ì¡°íšŒ
        currentNode, err := ufs.dagService.Get(ctx, currentCID)
        if err != nil {
            return nil, fmt.Errorf("failed to get node: %w", err)
        }

        // UnixFS ë©”íƒ€ë°ì´í„° íŒŒì‹±
        fsNode, err := unixfs.FSNodeFromBytes(currentNode.RawData())
        if err != nil {
            return nil, fmt.Errorf("failed to parse UnixFS node: %w", err)
        }

        // ë””ë ‰í„°ë¦¬ì¸ì§€ í™•ì¸
        if fsNode.Type() != unixfs.TDirectory {
            return nil, fmt.Errorf("path segment '%s' is not a directory", segment)
        }

        // 3. ë””ë ‰í„°ë¦¬ì—ì„œ í•´ë‹¹ ì´ë¦„ì˜ ë§í¬ ì°¾ê¸°
        found := false
        for _, link := range currentNode.Links() {
            if link.Name == segment {
                currentCID = link.Cid
                found = true
                break
            }
        }

        if !found {
            return nil, fmt.Errorf("path segment '%s' not found", segment)
        }
    }

    // 4. ìµœì¢… ë…¸ë“œ ë°˜í™˜
    return ufs.Get(ctx, currentCID)
}
```

## ğŸƒâ€â™‚ï¸ ì‹¤ìŠµ ê°€ì´ë“œ

### 1. ê¸°ë³¸ ì‹¤í–‰

```bash
cd 03-unixfs
go run main.go
```

**ì˜ˆìƒ ì¶œë ¥**:
```
=== UnixFS Demo ===

1. Setting up UnixFS with 256KB chunks:
   âœ… UnixFS initialized with chunk size: 262144 bytes

2. Adding various file types:
   ğŸ“„ Adding text file:
   âœ… Text file â†’ bafkreigh2akiscai...
   ğŸ“„ Adding binary file:
   âœ… Binary file â†’ bafkreibc4uoyerf...
   ğŸ“„ Adding large file (1MB):
   âœ… Large file â†’ bafybeihdwdcwfw...

3. File retrieval and verification:
   âœ… Text file content matches
   âœ… Binary file content matches
   âœ… Large file content matches

4. Directory operations:
   ğŸ“ Creating nested directory structure:
   âœ… Directory â†’ bafybeigqkjhkr3y...

   ğŸ“‚ Directory listing:
   â”œâ”€ ğŸ“„ readme.txt (245 bytes)
   â”œâ”€ ğŸ“„ data.json (156 bytes)
   â””â”€ ğŸ“ subdir/
       â””â”€ ğŸ“„ nested.txt (89 bytes)

5. Path-based file access:
   âœ… /readme.txt â†’ "This is a README file..."
   âœ… /subdir/nested.txt â†’ "Nested file content"
   âœ… /data.json â†’ {"name": "test", "value": 42}

6. Chunking demonstration:
   ğŸ“Š Large file chunking analysis:
      File size: 1048576 bytes
      Chunk size: 262144 bytes
      Number of chunks: 4
      Chunk distribution: [262144, 262144, 262144, 262144]
```

### 2. ì²­í‚¹ ì „ëµ ì‹¤í—˜

ë‹¤ì–‘í•œ ì²­í¬ í¬ê¸°ë¡œ ì„±ëŠ¥ ë¹„êµ:

```bash
# ì‘ì€ ì²­í¬ (64KB)
UnixFS_CHUNK_SIZE=65536 go run main.go

# í° ì²­í¬ (1MB)
UnixFS_CHUNK_SIZE=1048576 go run main.go

# ê¸°ë³¸ê°’ (256KB)
go run main.go
```

**ê´€ì°° í¬ì¸íŠ¸**:
- ì²­í¬ í¬ê¸°ê°€ ì‘ì„ìˆ˜ë¡ ë” ë§ì€ ì²­í¬ ìƒì„±
- ì²­í¬ í¬ê¸°ê°€ í´ìˆ˜ë¡ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€
- ë„¤íŠ¸ì›Œí¬ ì¡°ê±´ì— ë”°ë¥¸ ìµœì  ì²­í¬ í¬ê¸° ë³€í™”

### 3. ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸

```go
// 10MB íŒŒì¼ ìƒì„± ë° ì²˜ë¦¬
func testLargeFile() {
    largeData := make([]byte, 10*1024*1024)
    for i := range largeData {
        largeData[i] = byte(i % 256)
    }

    file := files.NewBytesFile(largeData)
    cid, err := unixfsWrapper.Put(ctx, file)
    // ì²­í‚¹ ë° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê´€ì°°
}
```

### 4. í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```bash
go test -v ./...
```

**ì£¼ìš” í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤**:
- âœ… ì‘ì€ íŒŒì¼ ì €ì¥/ê²€ìƒ‰
- âœ… ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²­í‚¹
- âœ… ë””ë ‰í„°ë¦¬ êµ¬ì¡° ìƒì„±
- âœ… ê²½ë¡œ ê¸°ë°˜ ì ‘ê·¼
- âœ… ìŠ¤íŠ¸ë¦¬ë° I/O ì„±ëŠ¥

## ğŸ” ê³ ê¸‰ í™œìš© ì‚¬ë¡€

### 1. ì›¹ì‚¬ì´íŠ¸ í˜¸ìŠ¤íŒ…

```go
type WebsiteBuilder struct {
    unixfs *UnixFsWrapper
}

func (wb *WebsiteBuilder) BuildSite(sitePath string) (cid.Cid, error) {
    // 1. HTML, CSS, JS íŒŒì¼ë“¤ì„ ìˆ˜ì§‘
    var htmlFiles []files.File
    var assetFiles []files.File

    err := filepath.Walk(sitePath, func(path string, info os.FileInfo, err error) error {
        if err != nil {
            return err
        }

        if !info.IsDir() {
            file, err := os.Open(path)
            if err != nil {
                return err
            }

            switch filepath.Ext(path) {
            case ".html":
                htmlFiles = append(htmlFiles, files.NewReaderFile(file))
            case ".css", ".js", ".png", ".jpg":
                assetFiles = append(assetFiles, files.NewReaderFile(file))
            }
        }
        return nil
    })

    // 2. ì›¹ì‚¬ì´íŠ¸ ë””ë ‰í„°ë¦¬ êµ¬ì¡° ìƒì„±
    websiteDir := files.NewMapDirectory(map[string]files.Node{
        "index.html": htmlFiles[0],
        "assets":     files.NewMapDirectory(assetsMap),
    })

    // 3. ì „ì²´ ì‚¬ì´íŠ¸ë¥¼ IPFSì— ì¶”ê°€
    return wb.unixfs.Put(ctx, websiteDir)
}
```

### 2. ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ

```go
type VersionedFile struct {
    Content     []byte            `json:"content"`
    Version     int               `json:"version"`
    PreviousRef map[string]string `json:"previous,omitempty"` // CID ë§í¬
    Timestamp   string            `json:"timestamp"`
    Author      string            `json:"author"`
    Message     string            `json:"message"`
}

func (vcs *VersionControlSystem) CommitFile(content []byte, message, author string,
                                          previousCID *cid.Cid) (cid.Cid, error) {
    version := 1
    var previousRef map[string]string

    if previousCID != nil {
        // ì´ì „ ë²„ì „ ì •ë³´ ì¡°íšŒí•˜ì—¬ ë²„ì „ ë²ˆí˜¸ ì¦ê°€
        version = getPreviousVersion(*previousCID) + 1
        previousRef = map[string]string{"/": previousCID.String()}
    }

    versionedFile := VersionedFile{
        Content:     content,
        Version:     version,
        PreviousRef: previousRef,
        Timestamp:   time.Now().Format(time.RFC3339),
        Author:      author,
        Message:     message,
    }

    // JSONìœ¼ë¡œ ì§ë ¬í™”í•˜ì—¬ ì €ì¥
    data, _ := json.Marshal(versionedFile)
    file := files.NewBytesFile(data)
    return vcs.unixfs.Put(ctx, file)
}
```

### 3. ë¶„ì‚° íŒŒì¼ ë°±ì—…

```go
type BackupSystem struct {
    unixfs *UnixFsWrapper
}

func (bs *BackupSystem) BackupDirectory(sourcePath string) (*BackupManifest, error) {
    manifest := &BackupManifest{
        Timestamp: time.Now(),
        Files:     make(map[string]FileInfo),
    }

    err := filepath.Walk(sourcePath, func(path string, info os.FileInfo, err error) error {
        if err != nil || info.IsDir() {
            return err
        }

        // 1. íŒŒì¼ í•´ì‹œ ê³„ì‚° (ì¤‘ë³µ ì œê±°)
        fileHash := calculateFileHash(path)

        // 2. ì¤‘ë³µì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì—…ë¡œë“œ
        if !bs.isDuplicate(fileHash) {
            file, err := os.Open(path)
            if err != nil {
                return err
            }
            defer file.Close()

            cid, err := bs.unixfs.Put(ctx, files.NewReaderFile(file))
            if err != nil {
                return err
            }

            // 3. ë§¤ë‹ˆí˜ìŠ¤íŠ¸ì— íŒŒì¼ ì •ë³´ ê¸°ë¡
            relativePath, _ := filepath.Rel(sourcePath, path)
            manifest.Files[relativePath] = FileInfo{
                CID:      cid.String(),
                Size:     info.Size(),
                ModTime:  info.ModTime(),
                Hash:     fileHash,
            }
        }

        return nil
    })

    // 4. ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìì²´ë„ IPFSì— ì €ì¥
    manifestData, _ := json.Marshal(manifest)
    manifestFile := files.NewBytesFile(manifestData)
    manifestCID, err := bs.unixfs.Put(ctx, manifestFile)

    manifest.ManifestCID = manifestCID.String()
    return manifest, err
}
```

### 4. ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¬ë°

```go
type MediaStreamer struct {
    unixfs *UnixFsWrapper
}

func (ms *MediaStreamer) StreamVideo(videoCID cid.Cid,
                                   startByte, endByte int64) (io.Reader, error) {
    // 1. ë¹„ë””ì˜¤ íŒŒì¼ ë…¸ë“œ ì¡°íšŒ
    videoNode, err := ms.unixfs.Get(ctx, videoCID)
    if err != nil {
        return nil, err
    }

    videoFile, ok := videoNode.(files.File)
    if !ok {
        return nil, fmt.Errorf("not a file")
    }

    // 2. ë²”ìœ„ ê¸°ë°˜ ì½ê¸° (HTTP Range Request ì§€ì›)
    if startByte > 0 {
        _, err = videoFile.Seek(startByte, io.SeekStart)
        if err != nil {
            return nil, err
        }
    }

    // 3. ì œí•œëœ í¬ê¸°ë§Œ ì½ëŠ” ë¦¬ë” ë°˜í™˜
    if endByte > startByte {
        return io.LimitReader(videoFile, endByte-startByte+1), nil
    }

    return videoFile, nil
}

func (ms *MediaStreamer) CreateVideoManifest(videoCID cid.Cid) (*HLSManifest, error) {
    // HLS (HTTP Live Streaming) ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ìƒì„±
    manifest := &HLSManifest{
        Version:    3,
        TargetDuration: 10,
        Segments:   []HLSSegment{},
    }

    // ë¹„ë””ì˜¤ë¥¼ 10ì´ˆ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë¶„í• í•˜ì—¬ ê°ê° CID ìƒì„±
    // ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” FFmpeg ë“±ì„ ì‚¬ìš©í•˜ì—¬ ì„¸ê·¸ë¨¼íŠ¸ ë¶„í• 

    return manifest, nil
}
```

## âš ï¸ ì£¼ì˜ì‚¬í•­ ë° ëª¨ë²” ì‚¬ë¡€

### 1. ì²­í¬ í¬ê¸° ì„ íƒ

```go
// âœ… ìš©ë„ë³„ ìµœì  ì²­í¬ í¬ê¸°
func selectChunkSize(fileSize int64, networkCondition string) int {
    switch {
    case fileSize < 1*1024*1024: // 1MB ë¯¸ë§Œ
        return 64 * 1024 // 64KB
    case networkCondition == "slow":
        return 128 * 1024 // 128KB
    case networkCondition == "fast":
        return 1024 * 1024 // 1MB
    default:
        return 256 * 1024 // 256KB (ê¸°ë³¸ê°’)
    }
}
```

### 2. ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬

```go
// âœ… ìŠ¤íŠ¸ë¦¬ë° ê¸°ë°˜ ì²˜ë¦¬
func processLargeFile(filePath string, ufs *UnixFsWrapper) error {
    file, err := os.Open(filePath)
    if err != nil {
        return err
    }
    defer file.Close()

    // íŒŒì¼ ì „ì²´ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œí•˜ì§€ ì•Šê³  ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ì²˜ë¦¬
    readerFile := files.NewReaderFile(file)
    _, err = ufs.Put(ctx, readerFile)
    return err
}

// âŒ ì˜ëª»ëœ ë°©ë²•: ë©”ëª¨ë¦¬ ë¶€ì¡± ìœ„í—˜
func processLargeFileWrong(filePath string, ufs *UnixFsWrapper) error {
    data, err := ioutil.ReadFile(filePath) // ì „ì²´ íŒŒì¼ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œ
    if err != nil {
        return err
    }

    file := files.NewBytesFile(data)
    _, err = ufs.Put(ctx, file)
    return err
}
```

### 3. ê²½ë¡œ ì •ê·œí™”

```go
// âœ… ì•ˆì „í•œ ê²½ë¡œ ì²˜ë¦¬
func normalizePath(path string) string {
    // ìƒëŒ€ ê²½ë¡œ ê³µê²© ë°©ì§€
    path = filepath.Clean(path)

    // ì ˆëŒ€ ê²½ë¡œë¥¼ ìƒëŒ€ ê²½ë¡œë¡œ ë³€í™˜
    if filepath.IsAbs(path) {
        path = path[1:]
    }

    // ë¹ˆ ê²½ë¡œ ì²˜ë¦¬
    if path == "." {
        return ""
    }

    return path
}
```

### 4. MIME íƒ€ì… ì²˜ë¦¬

```go
// âœ… ìë™ MIME íƒ€ì… ê°ì§€
func detectMimeType(filename string, content []byte) string {
    // 1. í™•ì¥ì ê¸°ë°˜ ê°ì§€
    ext := filepath.Ext(filename)
    if mimeType := mime.TypeByExtension(ext); mimeType != "" {
        return mimeType
    }

    // 2. ë‚´ìš© ê¸°ë°˜ ê°ì§€
    return http.DetectContentType(content)
}

func addFileWithMetadata(ufs *UnixFsWrapper, filename string,
                        content []byte) (cid.Cid, error) {
    mimeType := detectMimeType(filename, content)

    // ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥
    fileWithMeta := struct {
        Content  []byte `json:"content"`
        Filename string `json:"filename"`
        MimeType string `json:"mime_type"`
        Size     int64  `json:"size"`
    }{
        Content:  content,
        Filename: filename,
        MimeType: mimeType,
        Size:     int64(len(content)),
    }

    data, _ := json.Marshal(fileWithMeta)
    file := files.NewBytesFile(data)
    return ufs.Put(ctx, file)
}
```

## ğŸ”§ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: "chunk too large" ì—ëŸ¬

**ì›ì¸**: ì²­í¬ í¬ê¸°ê°€ ì‹œìŠ¤í…œ í•œê³„ë¥¼ ì´ˆê³¼
```go
// í•´ê²°: ì²­í¬ í¬ê¸° ì œí•œ
const MaxChunkSize = 1024 * 1024 // 1MB

func validateChunkSize(chunkSize int) int {
    if chunkSize > MaxChunkSize {
        log.Printf("Chunk size %d exceeds maximum, using %d", chunkSize, MaxChunkSize)
        return MaxChunkSize
    }
    return chunkSize
}
```

### ë¬¸ì œ 2: "out of memory" ì—ëŸ¬

**ì›ì¸**: ëŒ€ìš©ëŸ‰ íŒŒì¼ì„ í•œ ë²ˆì— ë©”ëª¨ë¦¬ì— ë¡œë“œ
```go
// í•´ê²°: ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
func processFileStream(reader io.Reader, ufs *UnixFsWrapper) (cid.Cid, error) {
    // io.Readerë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì†Œí™”
    file := files.NewReaderFile(reader)
    return ufs.Put(ctx, file)
}
```

### ë¬¸ì œ 3: "path not found" ì—ëŸ¬

**ì›ì¸**: ì˜ëª»ëœ ê²½ë¡œ ë˜ëŠ” ë””ë ‰í„°ë¦¬ êµ¬ì¡°
```go
// í•´ê²°: ê²½ë¡œ ìœ íš¨ì„± ê²€ì‚¬
func validatePath(ufs *UnixFsWrapper, rootCID cid.Cid, path string) error {
    pathSegments := strings.Split(strings.Trim(path, "/"), "/")

    for i := 0; i < len(pathSegments); i++ {
        partialPath := "/" + strings.Join(pathSegments[:i+1], "/")
        _, err := ufs.GetPath(ctx, rootCID, partialPath)
        if err != nil {
            return fmt.Errorf("invalid path at '%s': %w", partialPath, err)
        }
    }
    return nil
}
```

### ë¬¸ì œ 4: ì²­í‚¹ ë¶ˆì¼ì¹˜

**ì›ì¸**: ë‹¤ë¥¸ ì²­í¬ í¬ê¸°ë¡œ ì €ì¥ëœ íŒŒì¼ ì ‘ê·¼
```go
// í•´ê²°: ì²­í¬ ì •ë³´ ë©”íƒ€ë°ì´í„° ì €ì¥
type FileMetadata struct {
    ChunkSize    int    `json:"chunk_size"`
    TotalSize    int64  `json:"total_size"`
    ChunkCount   int    `json:"chunk_count"`
    Algorithm    string `json:"algorithm"`
}

func putFileWithMetadata(ufs *UnixFsWrapper, file files.File,
                        chunkSize int) (cid.Cid, error) {
    // íŒŒì¼ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ í•¨ê»˜ ì €ì¥
    metadata := FileMetadata{
        ChunkSize:  chunkSize,
        Algorithm:  "size-splitter",
    }

    // ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨í•œ wrapper êµ¬ì¡° ìƒì„±
    wrapper := struct {
        Metadata FileMetadata `json:"metadata"`
        Content  string       `json:"content"` // ì‹¤ì œ íŒŒì¼ CID
    }{
        Metadata: metadata,
    }

    // ì‹¤ì œ íŒŒì¼ ì €ì¥
    fileCID, err := ufs.Put(ctx, file)
    if err != nil {
        return cid.Undef, err
    }

    wrapper.Content = fileCID.String()

    // ë˜í¼ ì €ì¥
    wrapperData, _ := json.Marshal(wrapper)
    wrapperFile := files.NewBytesFile(wrapperData)
    return ufs.Put(ctx, wrapperFile)
}
```

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### 1. ë³‘ë ¬ ì²­í‚¹

```go
// âœ… ë³‘ë ¬ ì²­í¬ ì²˜ë¦¬
func putFileParallel(ufs *UnixFsWrapper, file files.File) (cid.Cid, error) {
    const workers = 4
    chunkQueue := make(chan []byte, workers*2)
    resultQueue := make(chan chunkResult, workers*2)

    // ì›Œì»¤ ì‹œì‘
    for i := 0; i < workers; i++ {
        go func() {
            for chunk := range chunkQueue {
                chunkFile := files.NewBytesFile(chunk)
                cid, err := ufs.Put(ctx, chunkFile)
                resultQueue <- chunkResult{cid: cid, err: err}
            }
        }()
    }

    // ì²­í‚¹ ë° íì— ì „ì†¡
    chunker := chunk.NewSizeSplitter(file, int64(ufs.maxChunkSize))
    var chunkCount int

    go func() {
        defer close(chunkQueue)
        for {
            chunk, err := chunker.NextBytes()
            if err == io.EOF {
                break
            }
            if err != nil {
                log.Printf("Chunking error: %v", err)
                return
            }
            chunkQueue <- chunk
            chunkCount++
        }
    }()

    // ê²°ê³¼ ìˆ˜ì§‘
    var links []*format.Link
    for i := 0; i < chunkCount; i++ {
        result := <-resultQueue
        if result.err != nil {
            return cid.Undef, result.err
        }
        links = append(links, &format.Link{Cid: result.cid})
    }

    // ë£¨íŠ¸ ë…¸ë“œ ìƒì„±
    return createRootNode(links)
}
```

### 2. ì§€ëŠ¥í˜• ìºì‹±

```go
// âœ… LRU ìºì‹œë¡œ ìì£¼ ì ‘ê·¼í•˜ëŠ” íŒŒì¼ ìºì‹±
type CachedUnixFS struct {
    *UnixFsWrapper
    cache *lru.Cache
}

func (cufs *CachedUnixFS) Get(ctx context.Context, c cid.Cid) (files.Node, error) {
    // ìºì‹œ í™•ì¸
    if cached, ok := cufs.cache.Get(c.String()); ok {
        return cached.(files.Node), nil
    }

    // ìºì‹œ ë¯¸ìŠ¤ ì‹œ ì‹¤ì œ ì¡°íšŒ
    node, err := cufs.UnixFsWrapper.Get(ctx, c)
    if err != nil {
        return nil, err
    }

    // ìºì‹œì— ì €ì¥ (í¬ê¸° ì œí•œ)
    if estimatedSize(node) < MaxCacheNodeSize {
        cufs.cache.Add(c.String(), node)
    }

    return node, nil
}
```

### 3. ì••ì¶• ì§€ì›

```go
// âœ… ìë™ ì••ì¶•ìœ¼ë¡œ ì €ì¥ ê³µê°„ ì ˆì•½
func putFileWithCompression(ufs *UnixFsWrapper, file files.File,
                          compress bool) (cid.Cid, error) {
    if !compress {
        return ufs.Put(ctx, file)
    }

    // gzip ì••ì¶• ì ìš©
    var buf bytes.Buffer
    gzipWriter := gzip.NewWriter(&buf)

    _, err := io.Copy(gzipWriter, file)
    if err != nil {
        return cid.Undef, err
    }

    err = gzipWriter.Close()
    if err != nil {
        return cid.Undef, err
    }

    // ì••ì¶•ëœ ë°ì´í„°ë¥¼ ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ì €ì¥
    compressed := CompressedFile{
        Data:             buf.Bytes(),
        OriginalSize:     getFileSize(file),
        CompressionType:  "gzip",
        Compressed:       true,
    }

    compressedData, _ := json.Marshal(compressed)
    compressedFile := files.NewBytesFile(compressedData)
    return ufs.Put(ctx, compressedFile)
}
```

## ğŸ“š ì¶”ê°€ í•™ìŠµ ìë£Œ

### ê´€ë ¨ ë¬¸ì„œ
- [UnixFS Specification](https://github.com/ipfs/specs/blob/master/UNIXFS.md)
- [IPFS File API](https://docs.ipfs.io/reference/kubo/rpc/#api-v0-add)
- [Merkle DAG Structure](https://docs.ipfs.io/concepts/merkle-dag/)
- [Chunking Strategies](https://docs.ipfs.io/concepts/file-systems/#chunking)

### ë‹¤ìŒ ë‹¨ê³„
1. **04-network-bitswap**: P2P ë„¤íŠ¸ì›Œí¬ì—ì„œ íŒŒì¼ ë¸”ë¡ êµí™˜
2. **05-pin-gc**: íŒŒì¼ ìƒëª…ì£¼ê¸° ê´€ë¦¬ì™€ ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
3. **06-gateway**: HTTPë¥¼ í†µí•œ íŒŒì¼ ì›¹ ì ‘ê·¼

## ğŸ“ ì—°ìŠµ ë¬¸ì œ

### ê¸°ì´ˆ ì—°ìŠµ
1. ë‹¤ì–‘í•œ í¬ê¸°ì˜ íŒŒì¼ì„ ì €ì¥í•˜ê³  ì²­í‚¹ ê²°ê³¼ë¥¼ ë¹„êµí•´ë³´ì„¸ìš”
2. ë””ë ‰í„°ë¦¬ êµ¬ì¡°ë¥¼ ë§Œë“¤ê³  ê²½ë¡œë¥¼ í†µí•´ íŒŒì¼ì— ì ‘ê·¼í•´ë³´ì„¸ìš”
3. ê°™ì€ íŒŒì¼ì„ ë‹¤ë¥¸ ì²­í¬ í¬ê¸°ë¡œ ì €ì¥í–ˆì„ ë•Œ CID ì°¨ì´ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”

### ì‹¬í™” ì—°ìŠµ
1. ì´ë¯¸ì§€ íŒŒì¼ì„ ì €ì¥í•˜ê³  ì¸ë„¤ì¼ ìƒì„± ì‹œìŠ¤í…œì„ ë§Œë“¤ì–´ë³´ì„¸ìš”
2. í…ìŠ¤íŠ¸ íŒŒì¼ì˜ ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œì„ êµ¬í˜„í•´ë³´ì„¸ìš”
3. ëŒ€ìš©ëŸ‰ ë¡œê·¸ íŒŒì¼ì„ íš¨ìœ¨ì ìœ¼ë¡œ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ì‹œìŠ¤í…œì„ ì„¤ê³„í•´ë³´ì„¸ìš”

### ì‹¤ì „ ê³¼ì œ
1. ì •ì  ì›¹ì‚¬ì´íŠ¸ í˜¸ìŠ¤íŒ… ì‹œìŠ¤í…œì„ ë§Œë“¤ì–´ë³´ì„¸ìš”
2. íŒŒì¼ ë°±ì—… ë° ë³µì› ë„êµ¬ë¥¼ êµ¬í˜„í•´ë³´ì„¸ìš”
3. ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¬ë° ì„œë¹„ìŠ¤ì˜ ê¸°ë³¸ êµ¬ì¡°ë¥¼ ì„¤ê³„í•´ë³´ì„¸ìš”

ì´ì œ IPFSì—ì„œ íŒŒì¼ê³¼ ë””ë ‰í„°ë¦¬ë¥¼ ì–´ë–»ê²Œ íš¨ìœ¨ì ìœ¼ë¡œ ë‹¤ë£¨ëŠ”ì§€ ì´í•´í•˜ì…¨ì„ ê²ƒì…ë‹ˆë‹¤. ë‹¤ìŒ ëª¨ë“ˆì—ì„œëŠ” P2P ë„¤íŠ¸ì›Œí¬ì—ì„œ ì´ëŸ¬í•œ ë°ì´í„°ë¥¼ ì–´ë–»ê²Œ ê³µìœ í•˜ëŠ”ì§€ í•™ìŠµí•˜ê² ìŠµë‹ˆë‹¤! ğŸš€